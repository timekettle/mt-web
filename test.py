from transformers import MarianMTModel, MarianTokenizer
import gradio as gr
import os
import json
import time
import requests
import openai
from loguru import logger
from datetime import datetime


class TranslationApp:
    def __init__(self, config_file, mapping_file):
        self.config_file = config_file
        self.mapping_file = mapping_file
        self.config_data = self.load_config()
        self.language_mapping, self.reverse_language_mapping = self.load_language_mapping()
        self.source_languages_display, self.lang_pairs, self.lang_pairs_display = self.get_lang_pairs_with_mapping()
        logger.add("output/user_log.txt", rotation="10 MB", retention=None, encoding="utf-8", level="INFO")

    
    
    def load_config(self):
        """åŠ è½½ config.json é…ç½®æ–‡ä»¶"""
        with open(self.config_file, 'r') as f:
            return json.load(f)

    def load_language_mapping(self):
        """åŠ è½½è¯­è¨€æ˜ å°„æ–‡ä»¶"""
        language_mapping = {}
        with open(self.mapping_file, 'r', encoding='utf-8') as f:
            for line in f:
                mapping = json.loads(line.strip())
                language_mapping.update(mapping)
        
        """åˆ›å»ºåå‘æ˜ å°„"""
        reverse_mapping = {v: k for k, v in language_mapping.items()}
        return language_mapping, reverse_mapping

    def get_lang_pairs_with_mapping(self):
        """è·å–è¯­è¨€å¯¹æ˜ å°„ï¼Œæ˜¾ç¤ºä¸­æ–‡åç§°"""
        source_languages = list(self.config_data.keys())
        lang_pairs = {src: list(targets.keys()) for src, targets in self.config_data.items()}


        source_languages_display = [self.language_mapping.get(src, src) for src in source_languages]
        lang_pairs_display = {
            self.language_mapping.get(src, src): [self.language_mapping.get(tgt, tgt) for tgt in tgts]
            for src, tgts in lang_pairs.items()
        }
        return source_languages_display, lang_pairs, lang_pairs_display

    def update_target_dropdown_with_mapping(self, src_lang_display):
        """æ›´æ–°ç›®æ ‡è¯­è¨€ä¸‹æ‹‰æ¡†"""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        if src_lang in self.lang_pairs:
            tgt_langs_display = [self.language_mapping.get(tgt, tgt) for tgt in self.lang_pairs[src_lang]]
            return gr.update(choices=tgt_langs_display, value=None)
        return gr.update(choices=[], value=None)

    def get_max_version_folder(self, langpair_folder):
        """è·å–æœ€æ–°æ¨¡å‹ç‰ˆæœ¬"""
        if not os.path.exists(langpair_folder) or not os.path.isdir(langpair_folder):
            return None
        file_list = []
        try:
            for folder in os.listdir(langpair_folder):
                if folder.startswith("checkpoint-"):
                    try:
                        version = int(folder.split("-")[1])
                        file_list.append((version, folder))
                    except (IndexError, ValueError):
                        continue
        except Exception as e:
            print(f"Error accessing langpair_folder: {e}")
            return None
        if len(file_list) == 0:
            return langpair_folder
        else:
            max_version_folder = max(file_list)[1]
            return os.path.join(langpair_folder, max_version_folder)

    def delayed_translation(self, text, model, tokenizer):
        """å»¶è¿Ÿç¿»è¯‘é€»è¾‘"""
        time.sleep(0.5)  # å»¶è¿Ÿ 0.5 ç§’
        if model and tokenizer and text:
            return self.perform_translation(text, model, tokenizer)
        return gr.update()
    
    def mask_language_token(self, input_ids: torch.Tensor, unk_token: int) -> torch.Tensor:
        """
        é’ˆå¯¹å¤šè¯­è¨€æ¨¡å‹ï¼Œéšæœºæ©ç›–æºè¯­ç§ã€ç›®æ ‡è¯­ç§
        """
        aug_type = random.choices(
            ["mask_src", "mask_tgt", "mask_both", "no_mask"],
            [0.15, 0.1, 0.05, 0.7]
        )[0]

        if aug_type == "mask_src":
            input_ids[0] = unk_token
        elif aug_type == "mask_tgt":
            input_ids[1] = unk_token
        elif aug_type == "mask_both":
            input_ids[0] = unk_token
            input_ids[1] = unk_token
        elif aug_type == "no_mask":
            pass

        return input_ids

    def add_language_ids(
        self, 
        inputs: str, 
        src_lang: str, 
        tgt_lang: str,
        ) -> torch.Tensor:
        inputs = tokenizer(inputs, return_tensors="pt", padding=True)

        # å€¼æ˜¯è¿™äº›è¯­è¨€æ ‡è¯†ç¬¦å¯¹åº”çš„æ•´æ•°ç´¢å¼•
        src_lang_id = torch.tensor([self.language_ids[f">>{src_lang}<<"]])
        tgt_lang_id = torch.tensor([self.language_ids[f">>{tgt_lang}<<"]])
        
        # å°†æºè¯­è¨€æ ‡è¯†ç¬¦ï¼ˆsrc_lang_idï¼‰ã€ç›®æ ‡è¯­è¨€æ ‡è¯†ç¬¦ï¼ˆtgt_lang_idï¼‰ä»¥åŠè¾“å…¥çš„ input_ids æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªæ–°çš„è¾“å…¥åºåˆ—ï¼Œå¹¶ä¼ é€’ç»™æ¨¡å‹ä»¥æ˜ç¡®æŒ‡å®šç¿»è¯‘æ–¹å‘ã€‚
        # e.g :
        # src_lang_id = torch.tensor([1]) # è‹±è¯­æ ‡è¯†ç¬¦ 
        # tgt_lang_id = torch.tensor([2]) # æ³•è¯­æ ‡è¯†ç¬¦
        # inputs["input_ids"][:-2] = torch.tensor([101, 7592, 1010, 2129])
        # tensor([1, 2, 101, 7592, 1010, 2129])
        inputs["input_ids"] = torch.cat(
            (src_lang_id, tgt_lang_id, inputs["input_ids"][:-2]), dim=-1
        )

        # æŒ‡ç¤ºå“ªäº›æ ‡è®°æ˜¯æœ‰æ•ˆçš„ï¼ˆå³éå¡«å……çš„ï¼‰ï¼Œç”¨äºæ¨¡å‹åœ¨è®¡ç®—æ—¶å¿½ç•¥å¡«å……éƒ¨åˆ†ã€‚1 è¡¨ç¤ºå®é™…çš„ï¼Œ0è¡¨ç¤ºpadding
        inputs["attention_mask"] = torch.cat(
            (torch.ones(2), inputs["attention_mask"][:-2]), dim=-1
        )
        inputs["labels"] = torch.cat((tgt_lang_id, inputs["labels"][:-1]), dim=-1)
        # random mask language token while training
        if self.mask_language_token:
            inputs["input_ids"] = self.augment.mask_language_token(
                inputs.get("input_ids"), unk_token=self.unk_token
            )

        inputs["src_lang"] = src_lang
        inputs["tgt_lang"] = tgt_lang
        return inputs
    
    def perform_translation(self, text, model, tokenizer):
        """æ‰§è¡Œç¿»è¯‘"""
        if model is None or tokenizer is None:
            return "è¯·å…ˆé€‰æ‹©è¯­è¨€å¯¹å¹¶åŠ è½½æ¨¡å‹ï¼"
        if not text:
            return ""
        try:
            logger.info(f"ç”¨æˆ·çš„è¾“å…¥æ˜¯{text}")
            inputs = tokenizer(text, return_tensors="pt", padding=True)
            outputs = model.generate(inputs["input_ids"])
            res = tokenizer.decode(outputs[0], skip_special_tokens=True)
            logger.info(f"è‡ªç ”æ¨¡å‹ç¿»è¯‘ç»“æœæ˜¯{res}")
            return res
        except Exception as e:
            return f"ç¿»è¯‘å‡ºé”™ï¼š{e}"

    def load_model_and_tokenizer(self, model_path):
        """åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨"""
        model_path = self.get_max_version_folder(model_path)
        if model_path is None or not os.path.isdir(model_path):
            return None, None, "failure"
        model = MarianMTModel.from_pretrained(model_path)
        tokenizer = MarianTokenizer.from_pretrained(model_path)
        return model, tokenizer, "success"

    def check_and_load_model(self, src_lang_display, tgt_lang_display, text, model, tokenizer):
        """æ£€æŸ¥è¯­è¨€å¯¹å¹¶åŠ è½½æ¨¡å‹"""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        tgt_lang = self.reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)

        logger.info("=============================================")
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logger.info(f"æ—¶é—´: {current_time}")

        if src_lang and tgt_lang:
            status, model_path = self.delayed_language_check(src_lang, tgt_lang)
            if model_path:
                logger.info(f"é€‰æ‹©çš„æºè¯­è¨€: {src_lang_display} ({src_lang}), ç›®æ ‡è¯­è¨€: {tgt_lang_display} ({tgt_lang})")
                logger.info(f"æ‰¾åˆ°çš„æ¨¡å‹è·¯å¾„: {model_path}")
                model, tokenizer, load_status = self.load_model_and_tokenizer(model_path)

                if load_status == "success":
                    if text:
                        translation = self.perform_translation(text, model, tokenizer)
                    else:
                        translation = gr.update()
                    return model, tokenizer, gr.update(interactive=True, placeholder="è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬..."), translation, model_path
                else:
                    return None, None, gr.update(interactive=False, placeholder="æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚"), gr.update(), None
            else:
                return None, None, gr.update(interactive=False, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚"), gr.update(), None
        return None, None, gr.update(interactive=False, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚"), gr.update(), None

    def delayed_language_check(self, src_lang, tgt_lang):
        """å»¶è¿Ÿæ£€æŸ¥è¯­è¨€å¯¹å¯ç”¨æ€§"""
        time.sleep(0.5)
        model_path, exists = self.config_data.get(src_lang, {}).get(tgt_lang, None), src_lang in self.config_data and tgt_lang in self.config_data[src_lang]
        if exists:
            return "success", model_path
        else:
            return "failure", None

    def perform_gpt_translation(self, text, src_lang_display, tgt_lang_display):
        """ä½¿ç”¨GPT-4oç¿»è¯‘"""
        if not text:
            return ""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        tgt_lang = self.reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)
        client = openai.AzureOpenAI(
            azure_endpoint="https://tlsm-gpt4o-test2.openai.azure.com/",
            api_key="2dd9bb411f6741f6bebfddb016a3698f",
            api_version="2024-07-01-preview",
        )
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘å‘˜ï¼Œåªè¾“å‡ºç›®æ ‡è¯­è¨€çš„ç¿»è¯‘ç»“æœ"},
                    {"role": "user", "content": f"æºè¯­è¨€æ˜¯ {src_lang}, å†…å®¹æ˜¯ï¼š{text}ï¼Œç›®æ ‡è¯­è¨€æ˜¯{tgt_lang}ï¼Œä½ éœ€è¦å…ˆæŠŠå†…å®¹å…¨éƒ¨è½¬åŒ–å°å†™å†ç¿»è¯‘"}
                ]
            )

            logger.info(f"GPT-4oç¿»è¯‘ç»“æœæ˜¯{response.choices[0].message.content}")
            return response.choices[0].message.content
        except Exception as e:
            return "Translation failed."

    def save_badcase(self, comments, input_text, output_text, google_output_text, src_lang_display, tgt_lang_display, model_path):
        """ä¿å­˜åé¦ˆ"""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        tgt_lang = self.reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)
        badcase = {
            "comments": comments,
            "input_text": input_text,
            "output_text": output_text,
            "google_output_text": google_output_text,
            "src_lang": src_lang,
            "tgt_lang": tgt_lang,
            "model_path": model_path
        }
        with open("output/badcase.jsonl", "a", encoding="utf-8") as f:
            f.write(json.dumps(badcase, ensure_ascii=False, indent=2) + "\n")
        return "åé¦ˆå·²ä¿å­˜æˆåŠŸï¼"

    def launch_app(self):
        with gr.Blocks() as demo:
            gr.HTML("""
            <div style="display: flex; align-items: center; padding-top: 10px;">
                <a href="https://cn.timekettle.co" target="_blank" style="margin-right: 10px;">
                    <img style="width: 120px; height: 120px; border-radius: 80px; max-width: 120px;" 
                         title="å‰å¾€æ—¶ç©ºå£¶"
                         src="https://26349372.s21i.faiusr.com/4/ABUIABAEGAAgmIf5gwYoluervAUwjBE4sRM.png">
                </a>
                <div style="text-align: left;">
                    <h1 style="margin: 0; font-size: 32px;">æ—¶ç©ºå£¶ç¿»è¯‘ Demo</h1>
                    <h2 style="margin: 0; font-size: 16px; color: gray; text-align: left;">åŸºäºMarianæœºå™¨ç¿»è¯‘æ¨¡å‹ï¼Œæ”¯æŒGPT-4oç¿»è¯‘å¯¹ç…§</h2>
                </div>
            </div>
            """)

            with gr.Row():
                with gr.Column():
                    src_lang_dropdown = gr.Dropdown(choices=self.source_languages_display, label="æºè¯­è¨€", interactive=True)
                    input_text = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=13, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚", interactive=False)
                with gr.Column():
                    tgt_lang_dropdown = gr.Dropdown(choices=[], label="ç›®æ ‡è¯­è¨€", interactive=True)
                    output_text = gr.Textbox(label="æ¨¡å‹ç¿»è¯‘ç»“æœ", lines=5, interactive=False)
                    google_output_text = gr.Textbox(label="GPT-4oç¿»è¯‘ç»“æœ", lines=5, interactive=False)

            with gr.Row():
                google_translate_button = gr.Button("ä½¿ç”¨GPT-4oç¿»è¯‘", elem_id="google_translate_button")

            with gr.Row():
                comments_textbox = gr.Textbox(label="æ¬¢è¿æ‚¨ç•™ä¸‹æ‚¨çš„æ„è§åé¦ˆ", lines=5, placeholder="æ„Ÿè°¢ä½¿ç”¨ï¼è§‰å¾—ç¿»è¯‘è¿˜è¡Œå—ï¼Ÿä¸å¦¨åœ¨ä¸‹é¢å†™ç‚¹åé¦ˆï¼Œæ‚¨çš„åæ§½æˆ–è¡¨æ‰¬éƒ½ä¼šè®©æˆ‘ä»¬çš„äº§å“æ›´ä¼˜ç§€å“¦ï¼ğŸ‰", elem_id="comments_textbox")
            with gr.Row():   
                save_badcase_button = gr.Button("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼Œå†™å®Œè¯·ç‚¹è¿™é‡Œæäº¤ï¼", elem_id="save_badcase_button")

            model_var = gr.State()
            tokenizer_var = gr.State()
            model_path_var = gr.State()

            src_lang_dropdown.change(fn=self.update_target_dropdown_with_mapping, 
                                    inputs=src_lang_dropdown, 
                                    outputs=tgt_lang_dropdown)

            tgt_lang_dropdown.change(fn=self.check_and_load_model,
                                    inputs=[src_lang_dropdown, tgt_lang_dropdown, input_text, model_var, tokenizer_var],
                                    outputs=[model_var, tokenizer_var, input_text, output_text, model_path_var])

            input_text.change(fn=self.perform_translation, 
                            inputs=[input_text, model_var, tokenizer_var], 
                            outputs=output_text)

            google_translate_button.click(fn=self.perform_gpt_translation, 
                                inputs=[input_text, src_lang_dropdown, tgt_lang_dropdown], 
                                outputs=google_output_text)

            save_badcase_button.click(fn=self.save_badcase,
                                    inputs=[comments_textbox, input_text, output_text, google_output_text, src_lang_dropdown, tgt_lang_dropdown, model_path_var],
                                    outputs=gr.Textbox(label="æäº¤çŠ¶æ€", value="ç­‰å¾…ç”¨æˆ·è¾“å…¥åé¦ˆï¼"))

        demo.css = """
        #google_translate_button {
            width: 300px;
            margin: 20px auto;
            padding: 10px 20px;
            font-size: 18px;
            font-weight: bold;
            color: blue;
            background-color: white;
            border: 2px solid blue;
            border-radius: 8px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        #google_translate_button:hover {
            background-color: blue;
            color: blue;
        }

        #google_translate_button:active {
            background-color: darkblue;
            color: white;
        }

        #save_badcase_button {
            width: 10px;  /* æ ¹æ®å†…å®¹è‡ªåŠ¨è°ƒæ•´å®½åº¦ */
            margin: 1px auto;
            padding: 10px; /* å‡å°å†…è¾¹è· */
            font-size: 16px;
            font-weight: bold;
            color: linear-gradient(135deg, #ffa07a, #ff7f50);
            background: linear-gradient(135deg, #ffa07a, #ff7f50);
            border: 2px solid linear-gradient(135deg, #ffa07a, #ff7f50);
            border-radius: 8px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        #save_badcase_button:hover {
            background: linear-gradient(135deg, #ff7f50, #ffa07a);
            color: linear-gradient(135deg, #ffa07a, #ff7f50);
        }

        #save_badcase_button:active {
            background: linear-gradient(135deg, #ffa07a, #ff7f50);
            color: linear-gradient(135deg, #ffa07a, #ff7f50);
        }

        #comments_textbox {
            width: 800px ; 
            margin: 0 auto; /* ä½¿å…¶å±…ä¸­ */
            font-size: 16px; /* è°ƒæ•´å­—ä½“å¤§å° */
            padding: 10px; /* å¢åŠ å†…è¾¹è· */
            box-sizing: border-box; /* ç¡®ä¿å®½åº¦åŒ…å«å†…è¾¹è· */
        }

        """
        demo.launch(server_name="0.0.0.0", server_port=7989)


if __name__ == "__main__":
    app = TranslationApp("config/user_config.json", "config/mapping.jsonl")
    app.launch_app()
