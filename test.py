from transformers import MarianMTModel, MarianTokenizer
import gradio as gr
import os
import json
import time
import requests
import openai
from loguru import logger
from datetime import datetime
# åŠ è½½ config.json å’Œ mapping.jsonl
config_file = 'config.json'
mapping_file = 'mapping.jsonl'

with open(config_file, 'r') as f:
    config_data = json.load(f)

# åŠ è½½è¯­è¨€æ˜ å°„
def load_language_mapping(mapping_file):
    language_mapping = {}
    with open(mapping_file, 'r', encoding='utf-8') as f:
        for line in f:
            mapping = json.loads(line.strip())
            language_mapping.update(mapping)
    # åˆ›å»ºåå‘æ˜ å°„ï¼šä¸­æ–‡ -> è‹±æ–‡
    reverse_mapping = {v: k for k, v in language_mapping.items()}
    return language_mapping, reverse_mapping

language_mapping, reverse_language_mapping = load_language_mapping(mapping_file)

# è·å–è¯­è¨€å¯¹ï¼Œç•Œé¢æ˜¾ç¤ºä¸­æ–‡ï¼Œå†…éƒ¨ä»ä½¿ç”¨è‹±æ–‡ç¼©å†™
def get_lang_pairs_with_mapping(config_data, language_mapping):
    source_languages = list(config_data.keys())
    lang_pairs = {src: list(targets.keys()) for src, targets in config_data.items()}

    # æ˜¾ç¤ºä¸ºä¸­æ–‡
    source_languages_display = [language_mapping.get(src, src) for src in source_languages]
    lang_pairs_display = {
        language_mapping.get(src, src): [language_mapping.get(tgt, tgt) for tgt in tgts]
        for src, tgts in lang_pairs.items()
    }
    return source_languages_display, lang_pairs, lang_pairs_display

# æ›´æ–°ç›®æ ‡è¯­è¨€ä¸‹æ‹‰æ¡†
def update_target_dropdown_with_mapping(src_lang_display):
    src_lang = reverse_language_mapping.get(src_lang_display, src_lang_display)
    if src_lang in lang_pairs:
        tgt_langs_display = [language_mapping.get(tgt, tgt) for tgt in lang_pairs[src_lang]]
        return gr.update(choices=tgt_langs_display, value=None)
    return gr.update(choices=[], value=None)

# è·å–æœ€æ–°æ¨¡å‹ç‰ˆæœ¬
def get_max_version_folder(langpair_folder):
    if not os.path.exists(langpair_folder) or not os.path.isdir(langpair_folder):
        return None
    file_list = []
    try:
        for folder in os.listdir(langpair_folder):
            if folder.startswith("checkpoint-"):
                try:
                    version = int(folder.split("-")[1])
                    file_list.append((version, folder))
                except (IndexError, ValueError):
                    continue
    except Exception as e:
        print(f"Error accessing langpair_folder: {e}")
        return None
    if len(file_list) == 0:
        return langpair_folder
        #return None
    else:
        max_version_folder = max(file_list)[1]
        return os.path.join(langpair_folder, max_version_folder)

def perform_translation(text, model, tokenizer): 
    """æ‰§è¡Œç¿»è¯‘"""
    if model is None or tokenizer is None:
        return "è¯·å…ˆé€‰æ‹©è¯­è¨€å¯¹å¹¶åŠ è½½æ¨¡å‹ï¼"  # æç¤ºç”¨æˆ·åŠ è½½æ¨¡å‹
    if not text:
        return ""  # å¦‚æœè¾“å…¥ä¸ºç©ºï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
    try:
        # å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œç¼–ç 
        inputs = tokenizer(text, return_tensors="pt", padding=True)
        # ä½¿ç”¨æ¨¡å‹ç”Ÿæˆç¿»è¯‘
        outputs = model.generate(inputs["input_ids"])
        # è§£ç è¾“å‡ºï¼Œå»æ‰ç‰¹æ®Šç¬¦å·
        res = tokenizer.decode(outputs[0], skip_special_tokens=True)
        logger.info(f"è‡ªç ”æ¨¡å‹ç¿»è¯‘ç»“æœæ˜¯{res}")
        return res
    except Exception as e:
        return f"ç¿»è¯‘å‡ºé”™ï¼š{e}"  # è¿”å›é”™è¯¯ä¿¡æ¯
def load_model_and_tokenizer(model_path):
    model_path = get_max_version_folder(model_path)
    if model_path is None or not os.path.isdir(model_path):
        return None, None, "failure"
    model = MarianMTModel.from_pretrained(model_path)
    tokenizer = MarianTokenizer.from_pretrained(model_path)
    return model, tokenizer, "success"
def check_and_load_model(src_lang_display, tgt_lang_display):
    """æ£€æŸ¥è¯­è¨€å¯¹å¹¶åŠ è½½å¯¹åº”çš„ç¿»è¯‘æ¨¡å‹"""
    src_lang = reverse_language_mapping.get(src_lang_display, src_lang_display)
    tgt_lang = reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)
    #logger.info(f"é€‰æ‹©çš„æºè¯­è¨€: {src_lang_display} ({src_lang}), ç›®æ ‡è¯­è¨€: {tgt_lang_display} ({tgt_lang})")
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info(f"æ—¶é—´: {current_time}")
    if src_lang and tgt_lang:  # ç¡®ä¿æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ä¸ä¸ºç©º
        # æ£€æŸ¥è¯­è¨€å¯¹æ˜¯å¦å¯ç”¨ï¼Œå¹¶è·å–æ¨¡å‹è·¯å¾„
        status, model_path = delayed_language_check(src_lang, tgt_lang)
        if model_path:  
            # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
            logger.info(f"é€‰æ‹©çš„æºè¯­è¨€: {src_lang_display} ({src_lang}), ç›®æ ‡è¯­è¨€: {tgt_lang_display} ({tgt_lang})")
            logger.info(f"æ‰¾åˆ°çš„æ¨¡å‹è·¯å¾„: {model_path}")
            model, tokenizer, load_status = load_model_and_tokenizer(model_path)

            if load_status == "success":
                # å¯ç”¨è¾“å…¥æ¡†
                return model, tokenizer, gr.update(
                    interactive=True, placeholder="è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬..."
                )
            else:
                return None, None, gr.update(
                    interactive=False, placeholder="æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚"
                )
        else:
            # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œç¦ç”¨è¾“å…¥æ¡†
            return None, None, gr.update(
                interactive=False, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚"
            )
    # å¦‚æœè¯­è¨€å¯¹æœªæŒ‡å®šï¼Œç¦ç”¨è¾“å…¥æ¡†
    return None, None, gr.update(
        interactive=False, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚"
    )


# å»¶è¿Ÿæ£€æŸ¥è¯­è¨€å¯¹å¯ç”¨æ€§
def delayed_language_check(src_lang, tgt_lang):
    time.sleep(0.5)
    model_path, exists = config_data.get(src_lang, {}).get(tgt_lang, None), src_lang in config_data and tgt_lang in config_data[src_lang]
    if exists:
        return "success", model_path
    else:
        return "failure", None

# GPT-4o ç¿»è¯‘
def perform_gpt_translation(text, src_lang_display, tgt_lang_display):
    if not text:
        return ""
    src_lang = reverse_language_mapping.get(src_lang_display, src_lang_display)
    tgt_lang = reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)
    client = openai.AzureOpenAI(
        azure_endpoint="https://tlsm-gpt4o-test2.openai.azure.com/",
        api_key="2dd9bb411f6741f6bebfddb016a3698f",
        api_version="2024-07-01-preview",
    )
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘å‘˜ï¼Œåªè¾“å‡ºç›®æ ‡è¯­è¨€çš„ç¿»è¯‘ç»“æœ"},
                {"role": "user", "content": f"æºè¯­è¨€æ˜¯ {src_lang}, å†…å®¹æ˜¯ï¼š{text}ï¼Œç›®æ ‡è¯­è¨€æ˜¯{tgt_lang}ï¼Œä½ éœ€è¦å…ˆæŠŠå†…å®¹å…¨éƒ¨è½¬åŒ–å°å†™å†ç¿»è¯‘"}
            ]
        )
        logger.info(f"ç”¨æˆ·çš„è¾“å…¥æ˜¯{text}")
        logger.info(f"GPT-4oç¿»è¯‘ç»“æœæ˜¯{response.choices[0].message.content}")
        return response.choices[0].message.content
    except Exception as e:
        return "Translation failed."

# Google ç¿»è¯‘
def perform_google_translation(text, src_lang_display, tgt_lang_display):
    if not text:
        return ""
    src_lang = reverse_language_mapping.get(src_lang_display, src_lang_display)
    tgt_lang = reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)
    url = "https://translation.googleapis.com/language/translate/v2"
    api_key = "AIzaSyAzVTWGdfo16u9KLXIl0fObVefb0kPih_U"
    params = {
        "q": text,
        "target": tgt_lang,
        "key": api_key
    }
    if src_lang:
        params["source"] = src_lang
    response = requests.get(url, params=params)
    if response.status_code == 200:
        result = response.json()
        return result["data"]["translations"][0]["translatedText"]
    else:
        return f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, é”™è¯¯ä¿¡æ¯: {response.text}"

# ä¿å­˜åé¦ˆ
def save_badcase(comments, input_text, output_text, google_output_text, src_lang_display, tgt_lang_display):
    src_lang = reverse_language_mapping.get(src_lang_display, src_lang_display)
    tgt_lang = reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)
    badcase = {
        "comments": comments,
        "input_text": input_text,
        "output_text": output_text,
        "google_output_text": google_output_text,
        "src_lang": src_lang,
        "tgt_lang": tgt_lang,
    }
    with open("badcase.jsonl", "a", encoding="utf-8") as f:
        f.write(json.dumps(badcase, ensure_ascii=False) + "\n")
    return "åé¦ˆå·²ä¿å­˜æˆåŠŸï¼"


with gr.Blocks() as demo:
    gr.HTML("<h1 style='text-align: center;'>æœºå™¨ç¿»è¯‘ç•Œé¢</h1>")

    logger.add("log.txt", 
           rotation="10 MB",   # æ–‡ä»¶è¾¾åˆ° 10 MB æ—¶åˆ›å»ºæ–°æ–‡ä»¶
           retention=None,     # è®¾ç½®ä¸º None è¡¨ç¤ºæ°¸ä¹…ä¿ç•™
           encoding="utf-8",   # ç¡®ä¿æ”¯æŒä¸­æ–‡
           level="INFO")    

    # åŠ è½½è¯­è¨€å¯¹æ˜ å°„
    source_languages_display, lang_pairs, lang_pairs_display = get_lang_pairs_with_mapping(config_data, language_mapping)

    with gr.Row():
        with gr.Column():
            src_lang_dropdown = gr.Dropdown(choices=source_languages_display, label="æºè¯­è¨€", interactive=True)

            input_text = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=13, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚", interactive=False)
        
        with gr.Column():
            tgt_lang_dropdown = gr.Dropdown(choices=[], label="ç›®æ ‡è¯­è¨€", interactive=True)
            output_text = gr.Textbox(label="æ¨¡å‹ç¿»è¯‘ç»“æœ", lines=5, interactive=False)
            google_output_text = gr.Textbox(label="GPT-4oç¿»è¯‘ç»“æœ", lines=5, interactive=False)
    
    with gr.Row():
        google_translate_button = gr.Button("ä½¿ç”¨GPT-4oç¿»è¯‘", elem_id="google_translate_button")

    with gr.Row():
        comments_textbox = gr.Textbox(label="æ¬¢è¿æ‚¨ç•™ä¸‹æ‚¨çš„æ„è§åé¦ˆ", lines=5, placeholder="æ„Ÿè°¢ä½¿ç”¨ï¼è§‰å¾—ç¿»è¯‘è¿˜è¡Œå—ï¼Ÿä¸å¦¨åœ¨ä¸‹é¢å†™ç‚¹åé¦ˆï¼Œæ‚¨çš„åæ§½æˆ–è¡¨æ‰¬éƒ½ä¼šè®©æˆ‘ä»¬çš„äº§å“æ›´ä¼˜ç§€å“¦ï¼ğŸ‰", elem_id="comments_textbox")
        save_badcase_button = gr.Button("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼Œå†™å®Œè¯·ç‚¹è¿™é‡Œï¼Œæ‚¨çš„æ¯ä¸€æ¬¡åé¦ˆéƒ½æ˜¯å¯¹æˆ‘ä»¬è¿›æ­¥çš„å¸®åŠ©ï¼", elem_id="save_badcase_button")
    
    model_var = gr.State()
    tokenizer_var = gr.State()

    src_lang_dropdown.change(fn=update_target_dropdown_with_mapping, inputs=src_lang_dropdown, outputs=tgt_lang_dropdown)


    tgt_lang_dropdown.change(
        fn=check_and_load_model,
        inputs=[src_lang_dropdown, tgt_lang_dropdown],
        outputs=[model_var, tokenizer_var, input_text]
    )


    

    input_text.change(fn=perform_translation, inputs=[input_text, model_var, tokenizer_var], outputs=output_text)

    google_translate_button.click(fn=perform_gpt_translation, inputs=[input_text, src_lang_dropdown, tgt_lang_dropdown], outputs=google_output_text)


    save_badcase_button.click(
        fn=save_badcase,
        inputs=[comments_textbox, input_text, output_text, google_output_text, src_lang_dropdown, tgt_lang_dropdown],
        outputs=gr.Textbox(label="æäº¤çŠ¶æ€", value="ç­‰å¾…ç”¨æˆ·è¾“å…¥åé¦ˆè¯„ä»·ï¼"),
    )

    gr.HTML("""
        <div style="text-align:center">           
            <br/>
            <br/>
            ä»…ä¾›å­¦ä¹ äº¤æµï¼Œä¸å¯ç”¨äºæˆ–éæ³•ç”¨é€”
            <br/>
        </div>
    """)

demo.css = """
#google_translate_button {
    width: 300px;
    margin: 20px auto;
    padding: 10px 20px;
    font-size: 18px;
    font-weight: bold;
    color: blue;
    background-color: white;
    border: 2px solid blue;
    border-radius: 8px;
    text-align: center;
    cursor: pointer;
    transition: all 0.3s ease;
}

#google_translate_button:hover {
    background-color: blue;
    color: blue;
}

#google_translate_button:active {
    background-color: darkblue;
    color: white;
}

#save_badcase_button {
    width: 10px;  /* æ ¹æ®å†…å®¹è‡ªåŠ¨è°ƒæ•´å®½åº¦ */
    margin: 1px auto;
    padding: 10px; /* å‡å°å†…è¾¹è· */
    font-size: 16px;
    font-weight: bold;
    color: linear-gradient(135deg, #ffa07a, #ff7f50);
    background: white;
    border: 2px solid linear-gradient(135deg, #ffa07a, #ff7f50);
    border-radius: 8px;
    text-align: center;
    cursor: pointer;
    transition: all 0.3s ease;
}

#save_badcase_button:hover {
    background: linear-gradient(135deg, #ff7f50, #ffa07a);
    color: linear-gradient(135deg, #ffa07a, #ff7f50);
}

#save_badcase_button:active {
    background: linear-gradient(135deg, #ffa07a, #ff7f50);
    color: linear-gradient(135deg, #ffa07a, #ff7f50);
}

#comments_textbox {
    width: 800px ; 
    margin: 0 auto; /* ä½¿å…¶å±…ä¸­ */
    font-size: 16px; /* è°ƒæ•´å­—ä½“å¤§å° */
    padding: 10px; /* å¢åŠ å†…è¾¹è· */
    box-sizing: border-box; /* ç¡®ä¿å®½åº¦åŒ…å«å†…è¾¹è· */
}



"""
demo.launch(server_name="0.0.0.0",server_port=7967)
