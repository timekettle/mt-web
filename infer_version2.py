# æ­¤ç‰ˆæœ¬å·²å®ç°æ‰€æœ‰åŠŸèƒ½ï¼ˆé™¤ä¸­è‹±æ–‡æ˜ å°„ï¼‰
from transformers import MarianMTModel, MarianTokenizer
import gradio as gr
import os
import json
import time
import requests
from google.cloud import translate_v2 as translate
import re
import html
from urllib import parse
import requests
import openai
# Load config file
config_file = 'config.json'
with open(config_file, 'r') as f:
    config_data = json.load(f)

# Helper functions
def get_lang_pairs(config_data):
    source_languages = list(config_data.keys())
    lang_pairs = {src: list(targets.keys()) for src, targets in config_data.items()}
    return source_languages, lang_pairs

def get_max_version_folder(langpair_folder):
    if not os.path.exists(langpair_folder) or not os.path.isdir(langpair_folder):
        return None
    file_list = []
    try:
        for folder in os.listdir(langpair_folder):
            if folder.startswith("checkpoint-"):
                try:
                    version = int(folder.split("-")[1])
                    file_list.append((version, folder))
                except (IndexError, ValueError):
                    continue
    except Exception as e:
        print(f"Error accessing langpair_folder: {e}")
        return None
    if len(file_list) == 0:
        return None
    else:
        max_version_folder = max(file_list)[1]
        return os.path.join(langpair_folder, max_version_folder)

def check_model_availability(src_lang, tgt_lang):
    if src_lang in config_data and tgt_lang in config_data[src_lang]:
        return config_data[src_lang][tgt_lang], True
    return None, False

def delayed_language_check(src_lang, tgt_lang):
    time.sleep(0.5)
    model_path, exists = check_model_availability(src_lang, tgt_lang)
    if exists:
        return "success", model_path
    else:
        return "failure", None

def load_model_and_tokenizer(model_path):
    model_path = get_max_version_folder(model_path)
    if model_path is None or not os.path.isdir(model_path):
        return None, None, "failure"
    model = MarianMTModel.from_pretrained(model_path)
    tokenizer = MarianTokenizer.from_pretrained(model_path)
    return model, tokenizer, "success"

def perform_translation(text, model, tokenizer):
    if model is None or tokenizer is None:
        return "è¯·å…ˆé€‰æ‹©è¯­è¨€å¯¹å¹¶åŠ è½½æ¨¡å‹ï¼"
    if not text:
        return ""
    inputs = tokenizer(text, return_tensors="pt", padding=True)
    outputs = model.generate(inputs["input_ids"])
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def update_target_dropdown(src_lang): 
    if isinstance(src_lang, list):
        src_lang = src_lang[0]
    if src_lang in lang_pairs:
        return gr.update(choices=lang_pairs[src_lang], value=None)
    return gr.update(choices=[], value=None)

def check_and_load_model(src_lang, tgt_lang):
    if src_lang and tgt_lang:
        status, model_path = delayed_language_check(src_lang, tgt_lang)
        if model_path:
            model, tokenizer, load_status = load_model_and_tokenizer(model_path)
            input_box_state = gr.update(
                interactive=True if load_status == "success" else False,
                placeholder="è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬..." if load_status == "success" else "è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚"
            )
            return model, tokenizer, input_box_state
        else:
            return None, None, gr.update(interactive=False, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚")
    return None, None, gr.update(interactive=False, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚")

def perform_gpt_translation(text, src_lang, tgt_lang):
    if not text:
        return ""
    client = openai.AzureOpenAI(
        azure_endpoint="https://tlsm-gpt4o-test2.openai.azure.com/",
        api_key="2dd9bb411f6741f6bebfddb016a3698f",
        api_version="2024-07-01-preview",
    )
    
    # è°ƒç”¨ OpenAI GPT-4 ç¿»è¯‘
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a professional translator. Please translate the following text."},
                {"role": "user", "content": f"The src_lang is {src_lang},Translate the following text into {tgt_lang}: {text}"}
            ]
        )
        # è¿”å›ç¿»è¯‘ç»“æœ
        return response.choices[0].message.content
    except Exception as e:
        return "Translation failed."

def perform_google_translation(text, src_lang, tgt_lang):
    if not text:
        return ""
    url = "https://translation.googleapis.com/language/translate/v2"
    api_key = "AIzaSyAzVTWGdfo16u9KLXIl0fObVefb0kPih_U"
    # æ„é€ è¯·æ±‚å‚æ•°
    params = {
        "q": text,  
        "target": tgt_lang, 
        "key": api_key  
    }
    if src_lang:
        params["source"] = src_lang
    response = requests.get(url, params=params)
    if response.status_code == 200:
        result = response.json()
        return result["data"]["translations"][0]["translatedText"]
    else:
        return f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, é”™è¯¯ä¿¡æ¯: {response.text}"


def save_badcase(comments, input_text, output_text, google_output_text, src_lang, tgt_lang):
    badcase = {
        "comments": comments,
        "input_text": input_text,
        "output_text": output_text,
        "google_output_text": google_output_text,
        "src_lang": src_lang,
        "tgt_lang": tgt_lang,
    }
    with open("badcase.jsonl", "a", encoding="utf-8") as f:
        f.write(json.dumps(badcase, ensure_ascii=False) + "\n")
    return "åé¦ˆå·²ä¿å­˜æˆåŠŸï¼"
source_languages, lang_pairs = get_lang_pairs(config_data)


with gr.Blocks() as demo:
    gr.HTML("<h1 style='text-align: center;'>æœºå™¨ç¿»è¯‘ç•Œé¢</h1>")
    
    with gr.Row():
        with gr.Column():
            src_lang_dropdown = gr.Dropdown(choices=source_languages, label="æºè¯­è¨€", interactive=True)
            input_text = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=13, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚", interactive=False)
        
        with gr.Column():
            tgt_lang_dropdown = gr.Dropdown(choices=[], label="ç›®æ ‡è¯­è¨€", interactive=True)
            output_text = gr.Textbox(label="æ¨¡å‹ç¿»è¯‘ç»“æœ", lines=5, interactive=False)
            google_output_text = gr.Textbox(label="GPT-4oç¿»è¯‘ç»“æœ", lines=5, interactive=False)
        
    with gr.Row():
        google_translate_button = gr.Button("ä½¿ç”¨Googleç¿»è¯‘", elem_id="google_translate_button")

    with gr.Row():
        comments_textbox = gr.Textbox(label="åé¦ˆ", lines=5, placeholder="æ„Ÿè°¢ä½¿ç”¨ï¼è§‰å¾—ç¿»è¯‘è¿˜è¡Œå—ï¼Ÿä¸å¦¨åœ¨ä¸‹é¢å†™ç‚¹åé¦ˆï¼Œæ‚¨çš„åæ§½æˆ–è¡¨æ‰¬éƒ½ä¼šè®©æˆ‘ä»¬çš„äº§å“æ›´ä¼˜ç§€å“¦ï¼ğŸ‰",elem_id="comments_textbox")
        save_badcase_button = gr.Button("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼Œå†™å®Œè¯·ç‚¹è¿™é‡Œï¼Œæ‚¨çš„æ¯ä¸€æ¬¡åé¦ˆéƒ½æ˜¯å¯¹æˆ‘ä»¬è¿›æ­¥çš„å¸®åŠ©ï¼", elem_id="save_badcase_button")
    
    model_var = gr.State()
    tokenizer_var = gr.State()

    src_lang_dropdown.change(fn=update_target_dropdown, inputs=src_lang_dropdown, outputs=tgt_lang_dropdown)

    tgt_lang_dropdown.change(
        fn=check_and_load_model,
        inputs=[src_lang_dropdown, tgt_lang_dropdown],
        outputs=[model_var, tokenizer_var, input_text]
    )

    input_text.change(fn=perform_translation, inputs=[input_text, model_var, tokenizer_var], outputs=output_text)

    google_translate_button.click(fn=perform_gpt_translation, inputs=[input_text, src_lang_dropdown, tgt_lang_dropdown], outputs=google_output_text)


    save_badcase_button.click(
        fn=save_badcase,
        inputs=[comments_textbox, input_text, output_text, google_output_text, src_lang_dropdown, tgt_lang_dropdown],
        outputs=gr.Textbox(label="çŠ¶æ€", value="ç­‰å¾…ç”¨æˆ·è¾“å…¥åé¦ˆè¯„ä»·ï¼"),
    )

# Add custom CSS for styling
demo.css = """
#google_translate_button {
    width: 300px;
    margin: 20px auto;
    padding: 10px 20px;
    font-size: 18px;
    font-weight: bold;
    color: blue;
    background-color: white;
    border: 2px solid blue;
    border-radius: 8px;
    text-align: center;
    cursor: pointer;
    transition: all 0.3s ease;
}

#google_translate_button:hover {
    background-color: blue;
    color: blue;
}

#google_translate_button:active {
    background-color: darkblue;
    color: white;
}

#save_badcase_button {
    width: 50px;  /* Set the desired width */
    margin: 10px auto;
    padding: 10px;
    font-size: 25px;
    font-weight: bold;
    color: linear-gradient(135deg, #ffa07a, #ff7f50);
    background: white;
    border: 2px solid linear-gradient(135deg, #ffa07a, #ff7f50);
    border-radius: 8px;
    text-align: center;
    cursor: pointer;
    transition: all 0.3s ease;
}

#save_badcase_button:hover {
    background: linear-gradient(135deg, #ff7f50, #ffa07a);
    color: linear-gradient(135deg, #ffa07a, #ff7f50);
}

#save_badcase_button:active {
    background: linear-gradient(135deg, #ffa07a, #ff7f50);
    color: linear-gradient(135deg, #ffa07a, #ff7f50);
}

#comments_textbox {
    width: 80%; /* è®¾ç½®å®½åº¦ä¸ºå®¹å™¨çš„ 80% */
    margin: 0 auto; /* ä½¿å…¶å±…ä¸­ */
    font-size: 16px; /* è°ƒæ•´å­—ä½“å¤§å° */
    padding: 10px; /* å¢åŠ å†…è¾¹è· */
    box-sizing: border-box; /* ç¡®ä¿å®½åº¦åŒ…å«å†…è¾¹è· */
}



"""
#demo.launch(server_port=7871)
demo.launch(server_port=7890)