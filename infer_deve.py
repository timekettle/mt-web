from transformers import MarianMTModel, MarianTokenizer
import gradio as gr
import os
import json
import time
import requests
import openai
from loguru import logger
from datetime import datetime
from typing import Dict,Tuple,List

class TranslationApp:
    def __init__(self, config_file: str):
        self.config_file = config_file
        self.config_data = self.load_config()
        self.language_mapping = self.get_language_mapping()
        self.reverse_language_mapping = self.get_reverse_language_mapping()
        self.source_languages_display, self.lang_pairs_display = self.get_lang_pairs_with_mapping()


    def load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(self.config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        return config["languages"] 

    def get_language_mapping(self):
        """è·å–è¯­è¨€å’Œå…¶æ˜ å°„åç§°"""
        return {lang_key: lang_data["name"] for lang_key, lang_data in self.config_data.items()}

    def get_reverse_language_mapping(self):
        """è·å–åå‘æ˜ å°„ï¼ˆæ˜¾ç¤ºåç§°åˆ°è¯­è¨€ç¼©å†™ï¼‰"""
        reverse_mapping = {}
        for lang_id, lang_data in self.config_data.items():
            reverse_mapping[lang_data["name"]] = lang_id
            for target_id, target_data in lang_data.get("targets", {}).items():
                reverse_mapping[target_data["name"]] = target_id
        return reverse_mapping

    def get_lang_pairs_with_mapping(self):
        """è·å–è¯­è¨€å¯¹æ˜ å°„"""
        source_languages_display = list(self.language_mapping.values())
        lang_pairs_display = {
            self.language_mapping[src_lang]: [
                self.config_data[src_lang]["targets"][tgt]["name"] 
                for tgt in self.config_data[src_lang]["targets"]
            ]
            for src_lang in self.config_data
        }
        return source_languages_display, lang_pairs_display

    def get_language_key(self, lang_display: str) -> str:
        """é€šè¿‡æ˜¾ç¤ºåç§°è·å–è¯­è¨€çš„ç¼©å†™"""
        for lang_key, lang_data in self.config_data.items():
            if lang_data["name"] == lang_display:
                return lang_key
        return lang_display

    def update_target_dropdown_with_mapping(self, src_lang_display):
        """æ›´æ–°ç›®æ ‡è¯­è¨€ä¸‹æ‹‰æ¡†"""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        if src_lang in self.config_data:
            tgt_langs_display = [
                self.config_data[src_lang]["targets"][tgt]["name"] 
                for tgt in self.config_data[src_lang]["targets"]
            ]
            return gr.update(choices=tgt_langs_display, value=None)
        return gr.update(choices=[], value=None)

    def update_model_dropdown(self, src_lang_display, tgt_lang_display):
        """æ›´æ–°æ¨¡å‹è·¯å¾„ä¸‹æ‹‰æ¡†"""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        tgt_lang = self.reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)  # ä¿®å¤ç›®æ ‡è¯­è¨€æ˜ å°„é—®é¢˜
        
        logger.info(f"æºè¯­è¨€æ˜ å°„: {src_lang_display} -> {src_lang}, ç›®æ ‡è¯­è¨€æ˜ å°„: {tgt_lang_display} -> {tgt_lang}")

        # æ£€æŸ¥ç›®æ ‡è¯­è¨€æ˜¯å¦æœ‰æ•ˆ
        if not tgt_lang_display or tgt_lang is None:
            logger.warning(f"ç›®æ ‡è¯­è¨€æœªé€‰æ‹©ï¼Œæ— æ³•æ›´æ–°æ¨¡å‹è·¯å¾„ã€‚æºè¯­è¨€æ˜ å°„: {src_lang_display} -> {src_lang}")
            return gr.update(choices=[], value=None)

        if src_lang in self.config_data and tgt_lang in self.config_data[src_lang]["targets"]:
            model_paths = self.config_data[src_lang]["targets"][tgt_lang].get("model_paths", [])
            logger.info(f"æ‰¾åˆ°çš„æ¨¡å‹è·¯å¾„: {model_paths}")
            return gr.update(choices=model_paths, value=None)
        else:
            logger.warning(f"è¯­è¨€å¯¹ ({src_lang}, {tgt_lang}) æ— æ³•æ‰¾åˆ°æ¨¡å‹è·¯å¾„")
        
        return gr.update(choices=[], value=None)




    def get_max_version_folder(self, langpair_folder):
        if not os.path.exists(langpair_folder) or not os.path.isdir(langpair_folder):
            return None
        file_list = []
        try:
            for folder in os.listdir(langpair_folder):
                if folder.startswith("checkpoint-"):
                    try:
                        version = int(folder.split("-")[1])
                        file_list.append((version, folder))
                    except (IndexError, ValueError):
                        continue
        except Exception as e:
            print(f"Error accessing langpair_folder: {e}")
            return None
        if len(file_list) == 0:
            return langpair_folder
        else:
            max_version_folder = max(file_list)[1]
            return os.path.join(langpair_folder, max_version_folder)

    def perform_translation(self, text, model, tokenizer):
        """æ‰§è¡Œç¿»è¯‘"""
        if model is None or tokenizer is None:
            return "è¯·å…ˆé€‰æ‹©è¯­è¨€å¯¹å¹¶åŠ è½½æ¨¡å‹ï¼"
        if not text:
            return ""
        try:
            logger.info(f"ç”¨æˆ·çš„è¾“å…¥æ˜¯{text}")
            inputs = tokenizer(text, return_tensors="pt", padding=True)
            outputs = model.generate(inputs["input_ids"])
            res = tokenizer.decode(outputs[0], skip_special_tokens=True)
            logger.info(f"è‡ªç ”æ¨¡å‹ç¿»è¯‘ç»“æœæ˜¯{res}")
            return res
        except Exception as e:
            return f"ç¿»è¯‘å‡ºé”™ï¼š{e}"

    def load_model_and_tokenizer(self, model_path):
        model_path = self.get_max_version_folder(model_path)
        if model_path is None or not os.path.isdir(model_path):
            return None, None, "failure"
        model = MarianMTModel.from_pretrained(model_path)
        tokenizer = MarianTokenizer.from_pretrained(model_path)
        return model, tokenizer, "success"
    


    def check_and_load_model(self, src_lang_display, tgt_lang_display, model_path, text, model, tokenizer):
        """æ£€æŸ¥è¯­è¨€å¯¹ã€åŠ è½½å¯¹åº”çš„ç¿»è¯‘æ¨¡å‹ï¼Œå¹¶å¤„ç†æ–‡æœ¬ç¿»è¯‘"""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        tgt_lang = self.reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)

        logger.info("=============================================")
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logger.info(f"æ—¶é—´: {current_time}")

        if src_lang and tgt_lang and model_path:  # ç¡®ä¿æºè¯­è¨€ã€ç›®æ ‡è¯­è¨€å’Œæ¨¡å‹è·¯å¾„éƒ½å·²é€‰æ‹©
            logger.info(f"æºè¯­è¨€: {src_lang_display} ({src_lang}), ç›®æ ‡è¯­è¨€: {tgt_lang_display} ({tgt_lang}), æ¨¡å‹è·¯å¾„: {model_path}")
            # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
            model, tokenizer, load_status = self.load_model_and_tokenizer(model_path)

            if load_status == "success":
                logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ")
                if text:  # å¦‚æœæœ‰è¾“å…¥æ–‡æœ¬ï¼Œæ‰§è¡Œç¿»è¯‘
                    translation = self.perform_translation(text, model, tokenizer)
                else:
                    translation = gr.update()
                return model, tokenizer, gr.update(interactive=True, placeholder="æ¨¡å‹å·²åŠ è½½ï¼Œè¾“å…¥æ–‡æœ¬å¼€å§‹ç¿»è¯‘ã€‚"), translation,model_path
            else:
                # æ¨¡å‹åŠ è½½å¤±è´¥
                return None, None, gr.update(interactive=False, placeholder="æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚"), gr.update(), None
        
        # å¦‚æœè·¯å¾„æœªé€‰æ‹©ï¼Œç¦ç”¨è¾“å…¥æ¡†
        return None, None, gr.update(interactive=False, placeholder="è¯·å…ˆé€‰æ‹©æ¨¡å‹è·¯å¾„ã€‚"), gr.update(), None


    def perform_gpt_translation(self, text, src_lang_display, tgt_lang_display):
        if not text:
            return ""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        tgt_lang = self.reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)
        client = openai.AzureOpenAI(
            azure_endpoint="https://tlsm-gpt4o-test2.openai.azure.com/",
            api_key="2dd9bb411f6741f6bebfddb016a3698f",
            api_version="2024-07-01-preview",
        )
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘å‘˜ï¼Œåªè¾“å‡ºç›®æ ‡è¯­è¨€çš„ç¿»è¯‘ç»“æœ"},
                    {"role": "user", "content": f"æºè¯­è¨€æ˜¯ {src_lang}, å†…å®¹æ˜¯ï¼š{text}ï¼Œç›®æ ‡è¯­è¨€æ˜¯{tgt_lang}ï¼Œä½ éœ€è¦å…ˆæŠŠå†…å®¹å…¨éƒ¨è½¬åŒ–å°å†™å†ç¿»è¯‘"}
                ]
            )
            
            logger.info(f"GPT-4oç¿»è¯‘ç»“æœæ˜¯{response.choices[0].message.content}")
            return response.choices[0].message.content
        except Exception as e:
            return "Translation failed."
    
    def delayed_language_check(self, src_lang, tgt_lang):
        time.sleep(0.5)
        model_path, exists = self.config_data.get(src_lang, {}).get(tgt_lang, None), src_lang in self.config_data and tgt_lang in self.config_data[src_lang]
        if exists:
            return "success", model_path
        else:
            return "failure", None

    def save_badcase(self,comments, input_text, output_text, google_output_text, src_lang_display, tgt_lang_display, model_path):
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        tgt_lang = self.reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)
        badcase = {
            "comments": comments,
            "input_text": input_text,
            "output_text": output_text,
            "gpt_output_text": google_output_text,
            "src_lang": src_lang,
            "tgt_lang": tgt_lang,
            "model_path":model_path
        }
        with open("output/badcase.jsonl", "a", encoding="utf-8") as f:
            f.write(json.dumps(badcase, ensure_ascii=False,indent=2) + "\n")
        return "åé¦ˆå·²ä¿å­˜æˆåŠŸï¼"



if __name__ == "__main__":
    app = TranslationApp("config/deve_config.json")

    with gr.Blocks() as demo:
        gr.HTML("""
        <div style="display: flex; align-items: center; padding-top: 10px;">
        <!-- å›¾ç‰‡éƒ¨åˆ† -->
        <a href="https://cn.timekettle.co" target="_blank" style="margin-right: 10px;">
            <img style="width: 120px; height: 120px; border-radius: 80px; max-width: 120px;" 
                title="å‰å¾€æ—¶ç©ºå£¶"
                src="https://26349372.s21i.faiusr.com/4/ABUIABAEGAAgmIf5gwYoluervAUwjBE4sRM.png">
        </a>
        <!-- æ ‡é¢˜éƒ¨åˆ† -->
        <div style="text-align: left;">
            <h1 style="margin: 0; font-size: 32px;">æ—¶ç©ºå£¶ç¿»è¯‘(Timekettle Translator) Demo</h1>
            <h2 style="margin: 0; font-size: 16px; color: gray; text-align: left;">åŸºäºMarianæœºå™¨ç¿»è¯‘æ¨¡å‹ï¼Œæ”¯æŒGPT-4oç¿»è¯‘å¯¹ç…§ï¼Œå¼€å‘è€…ä½¿ç”¨ç‰ˆ</h2>
        </div>
        </div>
        """)

        logger.add("output/deve_log.txt", rotation="10 MB", retention=None, encoding="utf-8", level="INFO")

        with gr.Row():
            with gr.Column():
                src_lang_dropdown = gr.Dropdown(choices=app.source_languages_display, label="æºè¯­è¨€", interactive=True)
                input_text = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=13, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚", interactive=False)
            with gr.Column():
                # ç›®æ ‡è¯­è¨€é€‰æ‹©
                tgt_lang_dropdown = gr.Dropdown(choices=[], label="ç›®æ ‡è¯­è¨€", interactive=True)
                # æ¨¡å‹é€‰æ‹©
                model_dropdown = gr.Dropdown(choices=[], label="å…·ä½“æ¨¡å‹", interactive=True)
                output_text = gr.Textbox(label="æ¨¡å‹ç¿»è¯‘ç»“æœ", lines=5, interactive=False)
                google_output_text = gr.Textbox(label="GPT-4oç¿»è¯‘ç»“æœ", lines=5, interactive=False)
        with gr.Row():
            google_translate_button = gr.Button("ä½¿ç”¨GPT-4oç¿»è¯‘", elem_id="google_translate_button")

        with gr.Row():
            comments_textbox = gr.Textbox(label="æ¬¢è¿æ‚¨ç•™ä¸‹æ‚¨çš„æ„è§åé¦ˆ", lines=5, placeholder="æ„Ÿè°¢ä½¿ç”¨ï¼è§‰å¾—ç¿»è¯‘è¿˜è¡Œå—ï¼Ÿä¸å¦¨åœ¨ä¸‹é¢å†™ç‚¹åé¦ˆï¼Œæ‚¨çš„åæ§½æˆ–è¡¨æ‰¬éƒ½ä¼šè®©æˆ‘ä»¬çš„äº§å“æ›´ä¼˜ç§€å“¦ï¼ğŸ‰", elem_id="comments_textbox")
        with gr.Row():   
            save_badcase_button = gr.Button("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼Œå†™å®Œè¯·ç‚¹è¿™é‡Œæäº¤ï¼", elem_id="save_badcase_button")
        
        model_var = gr.State()
        tokenizer_var = gr.State()
        model_path_var = gr.State()

        # æºè¯­è¨€é€‰æ‹©æ›´æ–°ç›®æ ‡è¯­è¨€
        src_lang_dropdown.change(
            fn=app.update_target_dropdown_with_mapping,
            inputs=[src_lang_dropdown],
            outputs=[tgt_lang_dropdown]
        )

        # ç›®æ ‡è¯­è¨€é€‰æ‹©æ›´æ–°æ¨¡å‹è·¯å¾„
        tgt_lang_dropdown.change(
            fn=app.update_model_dropdown,
            inputs=[src_lang_dropdown, tgt_lang_dropdown],
            outputs=[model_dropdown]
        )

        # åŠ è½½æ¨¡å‹
        model_dropdown.change(
        fn=app.check_and_load_model,
        inputs=[src_lang_dropdown, tgt_lang_dropdown, model_dropdown, input_text, model_var, tokenizer_var],
        outputs=[model_var, tokenizer_var, input_text, output_text,model_path_var]
        )
        
        # ç”¨æˆ·è¾“å…¥å¹¶ç¿»è¯‘
        input_text.change(fn=app.perform_translation, 
                        inputs=[input_text, model_var, tokenizer_var], 
                        outputs=output_text)

        google_translate_button.click(fn=app.perform_gpt_translation, 
                        inputs=[input_text, src_lang_dropdown, tgt_lang_dropdown], 
                        outputs=google_output_text)


        save_badcase_button.click(
            fn=app.save_badcase,
            inputs=[comments_textbox, input_text, output_text, google_output_text, src_lang_dropdown, tgt_lang_dropdown,model_path_var],
            outputs=gr.Textbox(label="æäº¤çŠ¶æ€", value="ç­‰å¾…ç”¨æˆ·è¾“å…¥åé¦ˆè¯„ä»·ï¼"),
        )
    demo.css = """
    #google_translate_button {
        width: 300px;
        margin: 20px auto;
        padding: 10px 20px;
        font-size: 18px;
        font-weight: bold;
        color: blue;
        background-color: white;
        border: 2px solid blue;
        border-radius: 8px;
        text-align: center;
        cursor: pointer;
        transition: all 0.3s ease;
    }

    #google_translate_button:hover {
        background-color: blue;
        color: blue;
    }

    #google_translate_button:active {
        background-color: darkblue;
        color: white;
    }

    #save_badcase_button {
        width: 10px;  /* æ ¹æ®å†…å®¹è‡ªåŠ¨è°ƒæ•´å®½åº¦ */
        margin: 1px auto;
        padding: 10px; /* å‡å°å†…è¾¹è· */
        font-size: 16px;
        font-weight: bold;
        color: linear-gradient(135deg, #ffa07a, #ff7f50);
        background: linear-gradient(135deg, #ffa07a, #ff7f50);
        border: 2px solid linear-gradient(135deg, #ffa07a, #ff7f50);
        border-radius: 8px;
        text-align: center;
        cursor: pointer;
        transition: all 0.3s ease;
    }

    #save_badcase_button:hover {
        background: linear-gradient(135deg, #ff7f50, #ffa07a);
        color: linear-gradient(135deg, #ffa07a, #ff7f50);
    }

    #save_badcase_button:active {
        background: linear-gradient(135deg, #ffa07a, #ff7f50);
        color: linear-gradient(135deg, #ffa07a, #ff7f50);
    }

    #comments_textbox {
        width: 800px ; 
        margin: 0 auto; /* ä½¿å…¶å±…ä¸­ */
        font-size: 16px; /* è°ƒæ•´å­—ä½“å¤§å° */
        padding: 10px; /* å¢åŠ å†…è¾¹è· */
        box-sizing: border-box; /* ç¡®ä¿å®½åº¦åŒ…å«å†…è¾¹è· */
    }



    """
        

    demo.launch(server_name="0.0.0.0", server_port=7961)
