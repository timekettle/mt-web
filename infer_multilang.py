from transformers import MarianMTModel, MarianTokenizer
import gradio as gr
import os
import json
import time
import requests
import openai
from loguru import logger
from datetime import datetime
from transformers import MarianTokenizer
import torch

class TranslationApp:
    def __init__(self, config_file, mapping_file, multilanguage_config_file = "config/multilang_config.json"):
        self.config_file = config_file
        self.multilanguage_config_file = multilanguage_config_file
        self.mapping_file = mapping_file
        
        self.config_data = self.load_config()
        self.multilang_config = self.load_multilang_config()
        self.multi_language_choices = list(self.multilang_config.keys())
        self.language_mapping, self.reverse_language_mapping = self.load_language_mapping()
        self.source_languages_display, self.lang_pairs, self.lang_pairs_display = self.get_lang_pairs_with_mapping()
        
        logger.add("output/user_log.txt", rotation="10 MB", retention=None, encoding="utf-8", level="INFO")
        self.tokenizer = None
        self.language_ids = None
        self.model_path = None
        


    
    
    def load_config(self):
        """åŠ è½½ config.json é…ç½®æ–‡ä»¶"""
        with open(self.config_file, 'r') as f:
            return json.load(f)

    def load_multilang_config(self):
        """åŠ è½½å¤šè¯­ç§æ¨¡å‹çš„é…ç½®æ–‡ä»¶"""
        if not os.path.exists(self.multilanguage_config_file):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {self.multilanguage_config_file} æœªæ‰¾åˆ°ï¼")
        with open(self.multilanguage_config_file, 'r', encoding='utf-8') as f:
            return json.load(f)


    def load_language_mapping(self):
        """åŠ è½½è¯­è¨€æ˜ å°„æ–‡ä»¶"""
        language_mapping = {}
        with open(self.mapping_file, 'r', encoding='utf-8') as f:
            for line in f:
                mapping = json.loads(line.strip())
                language_mapping.update(mapping)
        
        """åˆ›å»ºåå‘æ˜ å°„"""
        reverse_mapping = {v: k for k, v in language_mapping.items()}
        return language_mapping, reverse_mapping

    def load_multilanguage_mapping(self):
        """åŠ è½½è¯­è¨€æ ‡è¯†ç¬¦åˆ°ä¸­æ–‡åç§°çš„æ˜ å°„"""
        if not os.path.exists(self.mapping_file):
            raise FileNotFoundError(f"è¯­è¨€æ˜ å°„æ–‡ä»¶ {self.mapping_file} æœªæ‰¾åˆ°ï¼")
        language_mapping = {}
        with open(self.mapping_file, 'r', encoding='utf-8') as f:
            for line in f:
                mapping = json.loads(line.strip())
                language_mapping.update(mapping)
        reverse_mapping = {v: k for k, v in language_mapping.items()}
        return language_mapping, reverse_mapping

    def get_lang_pairs_with_mapping(self):
        """è·å–è¯­è¨€å¯¹æ˜ å°„ï¼Œæ˜¾ç¤ºä¸­æ–‡åç§°"""
        source_languages = list(self.config_data.keys())
        lang_pairs = {src: list(targets.keys()) for src, targets in self.config_data.items()}


        source_languages_display = [self.language_mapping.get(src, src) for src in source_languages]
        lang_pairs_display = {
            self.language_mapping.get(src, src): [self.language_mapping.get(tgt, tgt) for tgt in tgts]
            for src, tgts in lang_pairs.items()
        }
        return source_languages_display, lang_pairs, lang_pairs_display

    def update_target_dropdown_with_mapping(self, src_lang_display):
        """æ›´æ–°ç›®æ ‡è¯­è¨€ä¸‹æ‹‰æ¡†"""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        if src_lang in self.lang_pairs:
            tgt_langs_display = [self.language_mapping.get(tgt, tgt) for tgt in self.lang_pairs[src_lang]]
            return gr.update(choices=tgt_langs_display, value=None)
        return gr.update(choices=[], value=None)

    def get_max_version_folder(self, langpair_folder):
        """è·å–æœ€æ–°æ¨¡å‹ç‰ˆæœ¬"""
        if not os.path.exists(langpair_folder) or not os.path.isdir(langpair_folder):
            return None
        file_list = []
        try:
            for folder in os.listdir(langpair_folder):
                if folder.startswith("checkpoint-"):
                    try:
                        version = int(folder.split("-")[1])
                        file_list.append((version, folder))
                    except (IndexError, ValueError):
                        continue
        except Exception as e:
            print(f"Error accessing langpair_folder: {e}")
            return None
        if len(file_list) == 0:
            return langpair_folder
        else:
            max_version_folder = max(file_list)[1]
            return os.path.join(langpair_folder, max_version_folder)

    def delayed_translation(self, text, model, tokenizer):
        """å»¶è¿Ÿç¿»è¯‘é€»è¾‘"""
        time.sleep(0.5)  # å»¶è¿Ÿ 0.5 ç§’
        if model and tokenizer and text:
            return self.perform_translation(text, model, tokenizer)
        return gr.update()
    
    def mask_language_token(self, input_ids: torch.Tensor, unk_token: int) -> torch.Tensor:
        """
        é’ˆå¯¹å¤šè¯­è¨€æ¨¡å‹ï¼Œéšæœºæ©ç›–æºè¯­ç§ã€ç›®æ ‡è¯­ç§
        """
        aug_type = random.choices(
            ["mask_src", "mask_tgt", "mask_both", "no_mask"],
            [0.15, 0.1, 0.05, 0.7]
        )[0]

        if aug_type == "mask_src":
            input_ids[0] = unk_token
        elif aug_type == "mask_tgt":
            input_ids[1] = unk_token
        elif aug_type == "mask_both":
            input_ids[0] = unk_token
            input_ids[1] = unk_token
        elif aug_type == "no_mask":
            pass

        return input_ids

    def add_language_ids(
        self, 
        inputs, 
        src_lang: str, 
        tgt_lang: str,
        ) -> torch.Tensor:

        
        #inputs = self.tokenizer(inputs, return_tensors="pt", padding=True)

        self.language_ids = {
                language: _id
                for language, _id in self.tokenizer.encoder.items()
                if language.startswith(">>") and language.endswith("<<")
        }

        # å€¼æ˜¯è¿™äº›è¯­è¨€æ ‡è¯†ç¬¦å¯¹åº”çš„æ•´æ•°ç´¢å¼•
        src_lang_id = torch.tensor([self.language_ids[f">>{src_lang}<<"]])
        tgt_lang_id = torch.tensor([self.language_ids[f">>{tgt_lang}<<"]])
        
        # å°†æºè¯­è¨€æ ‡è¯†ç¬¦ï¼ˆsrc_lang_idï¼‰ã€ç›®æ ‡è¯­è¨€æ ‡è¯†ç¬¦ï¼ˆtgt_lang_idï¼‰ä»¥åŠè¾“å…¥çš„ input_ids æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªæ–°çš„è¾“å…¥åºåˆ—ï¼Œå¹¶ä¼ é€’ç»™æ¨¡å‹ä»¥æ˜ç¡®æŒ‡å®šç¿»è¯‘æ–¹å‘ã€‚
        # e.g :
        # src_lang_id = torch.tensor([1]) # è‹±è¯­æ ‡è¯†ç¬¦ 
        # tgt_lang_id = torch.tensor([2]) # æ³•è¯­æ ‡è¯†ç¬¦
        # inputs["input_ids"][:-2] = torch.tensor([101, 7592, 1010, 2129])
        # tensor([1, 2, 101, 7592, 1010, 2129])
        inputs["input_ids"] = torch.cat(
            (src_lang_id, tgt_lang_id, inputs["input_ids"]), dim=-1
        ).unsqueeze(0)

        # æŒ‡ç¤ºå“ªäº›æ ‡è®°æ˜¯æœ‰æ•ˆçš„ï¼ˆå³éå¡«å……çš„ï¼‰ï¼Œç”¨äºæ¨¡å‹åœ¨è®¡ç®—æ—¶å¿½ç•¥å¡«å……éƒ¨åˆ†ã€‚1 è¡¨ç¤ºå®é™…çš„ï¼Œ0è¡¨ç¤ºpadding
        inputs["attention_mask"] = torch.cat(
            (torch.ones(2), inputs["attention_mask"]), dim=-1
        ).unsqueeze(0)


        inputs["src_lang"] = src_lang
        inputs["tgt_lang"] = tgt_lang

        inputs 
        return inputs
    
    def perform_translation(self, text, model, tokenizer):
        """æ‰§è¡Œç¿»è¯‘"""
        if model is None or tokenizer is None:
            return "è¯·å…ˆé€‰æ‹©è¯­è¨€å¯¹å¹¶åŠ è½½æ¨¡å‹ï¼"
        if not text:
            return ""
        try:
            logger.info(f"ç”¨æˆ·çš„è¾“å…¥æ˜¯{text}")
            inputs = tokenizer(text, return_tensors="pt", padding=True)
            outputs = model.generate(inputs["input_ids"])
            res = tokenizer.decode(outputs[0], skip_special_tokens=True)
            logger.info(f"è‡ªç ”æ¨¡å‹ç¿»è¯‘ç»“æœæ˜¯{res}")
            return res
        except Exception as e:
            return f"ç¿»è¯‘å‡ºé”™ï¼š{e}"

    def load_model_and_tokenizer(self, model_path):
        """åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨"""
        model_path = self.get_max_version_folder(model_path)
        if model_path is None or not os.path.isdir(model_path):
            return None, None, "failure"
        model = MarianMTModel.from_pretrained(model_path)
        tokenizer = MarianTokenizer.from_pretrained(model_path)
        self.tokenizer = tokenizer
        return model, tokenizer, "success"

    def check_and_load_model(self, src_lang_display, tgt_lang_display, text, model, tokenizer):
        """æ£€æŸ¥è¯­è¨€å¯¹å¹¶åŠ è½½æ¨¡å‹"""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        tgt_lang = self.reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)

        logger.info("=============================================")
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logger.info(f"æ—¶é—´: {current_time}")

        if src_lang and tgt_lang:
            status, model_path = self.delayed_language_check(src_lang, tgt_lang)
            if model_path:
                logger.info(f"é€‰æ‹©çš„æºè¯­è¨€: {src_lang_display} ({src_lang}), ç›®æ ‡è¯­è¨€: {tgt_lang_display} ({tgt_lang})")
                logger.info(f"æ‰¾åˆ°çš„æ¨¡å‹è·¯å¾„: {model_path}")
                model, tokenizer, load_status = self.load_model_and_tokenizer(model_path)

                if load_status == "success":
                    if text:
                        translation = self.perform_translation(text, model, tokenizer)
                    else:
                        translation = gr.update()
                    return model, tokenizer, gr.update(interactive=True, placeholder="è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬..."), translation, model_path
                else:
                    return None, None, gr.update(interactive=False, placeholder="æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚"), gr.update(), None
            else:
                return None, None, gr.update(interactive=False, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚"), gr.update(), None
        return None, None, gr.update(interactive=False, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚"), gr.update(), None

    def delayed_language_check(self, src_lang, tgt_lang):
        """å»¶è¿Ÿæ£€æŸ¥è¯­è¨€å¯¹å¯ç”¨æ€§"""
        time.sleep(0.5)
        model_path, exists = self.config_data.get(src_lang, {}).get(tgt_lang, None), src_lang in self.config_data and tgt_lang in self.config_data[src_lang]
        if exists:
            return "success", model_path
        else:
            return "failure", None

    def perform_gpt_translation(self, text, src_lang_display, tgt_lang_display):
        """ä½¿ç”¨GPT-4oç¿»è¯‘"""
        if not text:
            return ""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        tgt_lang = self.reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)
        client = openai.AzureOpenAI(
            azure_endpoint="https://tlsm-gpt4o-test2.openai.azure.com/",
            api_key="2dd9bb411f6741f6bebfddb016a3698f",
            api_version="2024-07-01-preview",
        )
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘å‘˜ï¼Œåªè¾“å‡ºç›®æ ‡è¯­è¨€çš„ç¿»è¯‘ç»“æœ"},
                    {"role": "user", "content": f"æºè¯­è¨€æ˜¯ {src_lang}, å†…å®¹æ˜¯ï¼š{text}ï¼Œç›®æ ‡è¯­è¨€æ˜¯{tgt_lang}ï¼Œä½ éœ€è¦å…ˆæŠŠå†…å®¹å…¨éƒ¨è½¬åŒ–å°å†™å†ç¿»è¯‘"}
                ]
            )

            logger.info(f"GPT-4oç¿»è¯‘ç»“æœæ˜¯{response.choices[0].message.content}")
            return response.choices[0].message.content
        except Exception as e:
            return "Translation failed."

    def save_badcase(self, comments, input_text, output_text, google_output_text, src_lang_display, tgt_lang_display, model_path):
        """ä¿å­˜åé¦ˆ"""
        src_lang = self.reverse_language_mapping.get(src_lang_display, src_lang_display)
        tgt_lang = self.reverse_language_mapping.get(tgt_lang_display, tgt_lang_display)
        badcase = {
            "comments": comments,
            "input_text": input_text,
            "output_text": output_text,
            "google_output_text": google_output_text,
            "src_lang": src_lang,
            "tgt_lang": tgt_lang,
            "model_path": model_path
        }
        with open("output/badcase.jsonl", "a", encoding="utf-8") as f:
            f.write(json.dumps(badcase, ensure_ascii=False, indent=2) + "\n")
        return "åé¦ˆå·²ä¿å­˜æˆåŠŸï¼"

    def launch_app(self):
        with gr.Blocks() as demo:
            with gr.Row():
                with gr.Column():
                    src_lang_dropdown = gr.Dropdown(choices=self.source_languages_display, label="æºè¯­è¨€", interactive=True)
                    input_text = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=13, placeholder="è¯·å…ˆé€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ã€‚", interactive=False)
                with gr.Column():
                    tgt_lang_dropdown = gr.Dropdown(choices=[], label="ç›®æ ‡è¯­è¨€", interactive=True)
                    output_text = gr.Textbox(label="æ¨¡å‹ç¿»è¯‘ç»“æœ", lines=5, interactive=False)
                    google_output_text = gr.Textbox(label="GPT-4oç¿»è¯‘ç»“æœ", lines=5, interactive=False)

            with gr.Row():
                google_translate_button = gr.Button("ä½¿ç”¨GPT-4oç¿»è¯‘", elem_id="google_translate_button")

            with gr.Row():
                comments_textbox = gr.Textbox(label="æ¬¢è¿æ‚¨ç•™ä¸‹æ‚¨çš„æ„è§åé¦ˆ", lines=5, placeholder="æ„Ÿè°¢ä½¿ç”¨ï¼è§‰å¾—ç¿»è¯‘è¿˜è¡Œå—ï¼Ÿä¸å¦¨åœ¨ä¸‹é¢å†™ç‚¹åé¦ˆï¼Œæ‚¨çš„åæ§½æˆ–è¡¨æ‰¬éƒ½ä¼šè®©æˆ‘ä»¬çš„äº§å“æ›´ä¼˜ç§€å“¦ï¼ğŸ‰", elem_id="comments_textbox")
            with gr.Row():   
                save_badcase_button = gr.Button("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼Œå†™å®Œè¯·ç‚¹è¿™é‡Œæäº¤ï¼", elem_id="save_badcase_button")

            model_var = gr.State()
            tokenizer_var = gr.State()
            model_path_var = gr.State()

            src_lang_dropdown.change(fn=self.update_target_dropdown_with_mapping, 
                                    inputs=src_lang_dropdown, 
                                    outputs=tgt_lang_dropdown)

            tgt_lang_dropdown.change(fn=self.check_and_load_model,
                                    inputs=[src_lang_dropdown, tgt_lang_dropdown, input_text, model_var, tokenizer_var],
                                    outputs=[model_var, tokenizer_var, input_text, output_text, model_path_var])

            input_text.change(fn=self.perform_translation, 
                            inputs=[input_text, model_var, tokenizer_var], 
                            outputs=output_text)

            google_translate_button.click(fn=self.perform_gpt_translation, 
                                inputs=[input_text, src_lang_dropdown, tgt_lang_dropdown], 
                                outputs=google_output_text)

            save_badcase_button.click(fn=self.save_badcase,
                                    inputs=[comments_textbox, input_text, output_text, google_output_text, src_lang_dropdown, tgt_lang_dropdown, model_path_var],
                                    outputs=gr.Textbox(label="æäº¤çŠ¶æ€", value="ç­‰å¾…ç”¨æˆ·è¾“å…¥åé¦ˆï¼"))

        demo.css = """
        #google_translate_button {
            width: 300px;
            margin: 20px auto;
            padding: 10px 20px;
            font-size: 18px;
            font-weight: bold;
            color: blue;
            background-color: white;
            border: 2px solid blue;
            border-radius: 8px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        #google_translate_button:hover {
            background-color: blue;
            color: blue;
        }

        #google_translate_button:active {
            background-color: darkblue;
            color: white;
        }

        #save_badcase_button {
            width: 10px;  /* æ ¹æ®å†…å®¹è‡ªåŠ¨è°ƒæ•´å®½åº¦ */
            margin: 1px auto;
            padding: 10px; /* å‡å°å†…è¾¹è· */
            font-size: 16px;
            font-weight: bold;
            color: linear-gradient(135deg, #ffa07a, #ff7f50);
            background: linear-gradient(135deg, #ffa07a, #ff7f50);
            border: 2px solid linear-gradient(135deg, #ffa07a, #ff7f50);
            border-radius: 8px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        #save_badcase_button:hover {
            background: linear-gradient(135deg, #ff7f50, #ffa07a);
            color: linear-gradient(135deg, #ffa07a, #ff7f50);
        }

        #save_badcase_button:active {
            background: linear-gradient(135deg, #ffa07a, #ff7f50);
            color: linear-gradient(135deg, #ffa07a, #ff7f50);
        }

        #comments_textbox {
            width: 800px ; 
            margin: 0 auto; /* ä½¿å…¶å±…ä¸­ */
            font-size: 16px; /* è°ƒæ•´å­—ä½“å¤§å° */
            padding: 10px; /* å¢åŠ å†…è¾¹è· */
            box-sizing: border-box; /* ç¡®ä¿å®½åº¦åŒ…å«å†…è¾¹è· */
        }

        """
        #demo.launch(server_name="0.0.0.0", server_port=7989)
    
    def get_multilang_model(self, model_name):
        """
        æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ååŠ è½½å¯¹åº”æ¨¡å‹
        """
        self.model_path = self.multilang_config.get(model_name)
        if self.model_path is None or not os.path.isdir(self.model_path):
            logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹æˆ–æ¨¡å‹è·¯å¾„æ— æ•ˆ: {model_name}")
            return gr.update(interactive=False, placeholder="æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")

        try:
            # åŠ è½½æ¨¡å‹å’Œ tokenizer
            model = MarianMTModel.from_pretrained(self.model_path)
            tokenizer = MarianTokenizer.from_pretrained(self.model_path)
            self.tokenizer = tokenizer  # æ›´æ–°ç±»ä¸­çš„ tokenizer
            self.model = model  # æ›´æ–°ç±»ä¸­çš„ model
            logger.info(f"æˆåŠŸåŠ è½½æ¨¡å‹: {model_name}, è·¯å¾„: {self.model_path}")

            return gr.update(interactive=False, placeholder="è¯·é€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€"),self.model_path
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½é”™è¯¯: {e}")
            return gr.update(interactive=False, placeholder="æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚"),None




    def update_source_languages(self, model_name):
        """
        åŠ è½½æ¨¡å‹æ—¶è§£æ train_info.jsonï¼Œå¹¶æ›´æ–°æºè¯­è¨€åˆ—è¡¨
        """
        model_path = self.multilang_config.get(model_name)
        if not model_path:
            return gr.update(choices=[], interactive=False), gr.update(choices=[], interactive=False)

        train_info_path = os.path.join(model_path, "train_info.json")
        if not os.path.isfile(train_info_path):
            return gr.update(choices=[], interactive=False), gr.update(choices=[], interactive=False)

        with open(train_info_path, 'r', encoding='utf-8') as f:
            train_info = json.load(f)

        lang_pairs = train_info.get("lang_pairs", {})
        source_languages = list(lang_pairs.keys())

        # åŠ è½½è¯­è¨€æ˜ å°„
        language_mapping, reverse_mapping = self.load_multilanguage_mapping()

        # å°†æºè¯­è¨€æ ‡è¯†ç¬¦è½¬æ¢ä¸ºä¸­æ–‡
        source_languages_chinese = [language_mapping.get(lang, lang) for lang in source_languages]
        
        # æ›´æ–°æºè¯­è¨€ä¸‹æ‹‰æ¡†
        return gr.update(choices=source_languages_chinese, interactive=True), gr.update(choices=[], interactive=False)

    
    def update_target_languages(self, source_lang, model_name):
        """
        æ ¹æ®æºè¯­è¨€åŠ¨æ€æ›´æ–°ç›®æ ‡è¯­è¨€é€‰é¡¹
        """
        model_path = self.multilang_config.get(model_name)
        if not model_path:
            return gr.update(choices=[], interactive=False)

        train_info_path = os.path.join(model_path, "train_info.json")
        if not os.path.isfile(train_info_path):
            return gr.update(choices=[], interactive=False)

        with open(train_info_path, 'r', encoding='utf-8') as f:
            train_info = json.load(f)

        lang_pairs = train_info.get("lang_pairs", {})
        
        # ç¡®ä¿ä»æºè¯­è¨€é€‰æ‹©ä¸­è·å–æ­£ç¡®çš„é”®å€¼
        # å¦‚æœ source_lang æ˜¯ä¸­æ–‡ï¼Œå¯èƒ½éœ€è¦å°†å…¶è½¬æ¢ä¸ºå¯¹åº”çš„è‹±æ–‡æˆ–æºè¯­è¨€æ ‡è¯†ç¬¦
        language_mapping, reverse_mapping = self.load_multilanguage_mapping()
        source_lang_key = reverse_mapping.get(source_lang, source_lang)  # è½¬æ¢ä¸ºæºè¯­è¨€æ ‡è¯†ç¬¦

        target_languages = lang_pairs.get(source_lang_key, [])

        # å°†ç›®æ ‡è¯­è¨€æ ‡è¯†ç¬¦è½¬æ¢ä¸ºä¸­æ–‡
        target_languages_chinese = [language_mapping.get(lang, lang) for lang in target_languages]

        return gr.update(choices=target_languages_chinese, interactive=True)


    # æ§åˆ¶è¾“å…¥æ¡†å¯ç”¨çŠ¶æ€
    def control_input_activation(self, source_lang, target_lang,model_name):
        """
        ç¡®ä¿å½“ç”¨æˆ·é€‰æ‹©äº†æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€æ—¶æ‰å¯ç”¨è¾“å…¥æ¡†
        """
        if source_lang and target_lang and model_name:
            return gr.update(interactive=True,placeholder="è¯·è¾“å…¥")
        else:
            return gr.update(interactive=False)


    def perform_multilang_translation(self, text, source_lang_chinese, target_lang_chinese):
        """
        æ‰§è¡Œå¤šè¯­ç§ç¿»è¯‘
        """
        if not text or not self.model or not self.tokenizer:
            return "è¯·å…ˆé€‰æ‹©å¤šè¯­ç§æ¨¡å‹å¹¶è®¾ç½®è¯­è¨€å¯¹ï¼"

        language_mapping, reverse_mapping = self.load_multilanguage_mapping()
        source_lang = reverse_mapping.get(source_lang_chinese, source_lang_chinese)
        target_lang = reverse_mapping.get(target_lang_chinese, target_lang_chinese)

            
        #formatted_text = f">>{target_lang}<< {text}"
        inputs = self.tokenizer(text, return_tensors="pt", padding=True)
        inputs = {k: v.squeeze(0) for k, v in inputs.items()}
        inputs = self.add_language_ids(inputs,source_lang, target_lang)
        outputs = self.model.generate(inputs["input_ids"])
        translation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return translation



    
    
    def render_layout(self):
        with gr.Blocks() as demo:
            gr.HTML("""
            <div style="display: flex; align-items: center; padding-top: 10px;">
                <a href="https://cn.timekettle.co" target="_blank" style="margin-right: 10px;">
                    <img style="width: 120px; height: 120px; border-radius: 80px; max-width: 120px;" 
                         title="å‰å¾€æ—¶ç©ºå£¶"
                         src="https://26349372.s21i.faiusr.com/4/ABUIABAEGAAgmIf5gwYoluervAUwjBE4sRM.png">
                </a>
                <div style="text-align: left;">
                    <h1 style="margin: 0; font-size: 32px;">æ—¶ç©ºå£¶ç¿»è¯‘ Demo</h1>
                    <h2 style="margin: 0; font-size: 16px; color: gray; text-align: left;">åŸºäºMarianæœºå™¨ç¿»è¯‘æ¨¡å‹ï¼Œæ”¯æŒGPT-4oç¿»è¯‘å¯¹ç…§</h2>
                </div>
            </div>
            """)
            with gr.Column():
                # ç”¨æˆ·é€‰æ‹©å•è¯­ç§æˆ–å¤šè¯­ç§ç¿»è¯‘
                mode_dropdown = gr.Dropdown(
                    choices=["å•è¯­ç§ç¿»è¯‘", "å¤šè¯­ç§ç¿»è¯‘"],
                    label="ç¿»è¯‘æ¨¡å¼",
                    value="å•è¯­ç§ç¿»è¯‘",
                    interactive=True,
                )

            # å•è¯­ç§ç¿»è¯‘å¸ƒå±€
            with gr.Column(visible=True) as single_language_row:
                self.launch_app()

            # å¤šè¯­ç§ç¿»è¯‘å¸ƒå±€
            with gr.Column(visible=False) as multi_language_row:
                model_status_output = gr.State()
                model_path_var = gr.State()

                # å¤šè¯­ç§æ¨¡å‹ä¸‹æ‹‰æ¡†
                multi_language_model_dropdown = gr.Dropdown(
                    choices=self.multi_language_choices,
                    label="é€‰æ‹©å¤šè¯­ç§æ¨¡å‹",
                    interactive=True,
                )
                with gr.Row():
                    with gr.Column():
                        # æºè¯­è¨€ä¸‹æ‹‰æ¡†
                        source_lang_dropdown = gr.Dropdown(
                            choices=[],  # åŠ¨æ€åŠ è½½
                            label="é€‰æ‹©æºè¯­è¨€",
                            interactive=False,
                        )
                        multi_input_text = gr.Textbox(
                                label="è¾“å…¥æ–‡æœ¬",
                                lines=13,
                                placeholder="è¯·é€‰æ‹©å¤šè¯­ç§æ¨¡å‹",
                                interactive=False,
                        )
                    with gr.Column():
                        # ç›®æ ‡è¯­è¨€ä¸‹æ‹‰æ¡†
                        target_lang_dropdown = gr.Dropdown(
                            choices=[],  # åŠ¨æ€åŠ è½½
                            label="é€‰æ‹©ç›®æ ‡è¯­è¨€",
                            interactive=False,
                        )

                        # è¾“å‡ºæ–‡æœ¬æ¡†
                        multi_output_text = gr.Textbox(
                            label="ç¿»è¯‘ç»“æœ", lines=5, interactive=False
                        )

                        # GPT-4o ç¿»è¯‘ç»“æœæ–‡æœ¬æ¡†
                        multi_google_output_text = gr.Textbox(
                            label="GPT-4oç¿»è¯‘ç»“æœ", lines=5, interactive=False
                        )

                with gr.Row():
                    google_translate_button = gr.Button("ä½¿ç”¨GPT-4oç¿»è¯‘", elem_id="google_translate_button")

                with gr.Row():
                    comments_textbox = gr.Textbox(label="æ¬¢è¿æ‚¨ç•™ä¸‹æ‚¨çš„æ„è§åé¦ˆ", lines=5, placeholder="æ„Ÿè°¢ä½¿ç”¨ï¼è§‰å¾—ç¿»è¯‘è¿˜è¡Œå—ï¼Ÿä¸å¦¨åœ¨ä¸‹é¢å†™ç‚¹åé¦ˆï¼Œæ‚¨çš„åæ§½æˆ–è¡¨æ‰¬éƒ½ä¼šè®©æˆ‘ä»¬çš„äº§å“æ›´ä¼˜ç§€å“¦ï¼ğŸ‰", elem_id="comments_textbox")
                with gr.Row():   
                    save_badcase_button = gr.Button("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼Œå†™å®Œè¯·ç‚¹è¿™é‡Œæäº¤ï¼", elem_id="save_badcase_button")

                
                # åŠ è½½å¤šè¯­ç§æ¨¡å‹
                multi_language_model_dropdown.change(
                    fn=self.get_multilang_model,  # åŠ è½½æ¨¡å‹
                    inputs=[multi_language_model_dropdown],
                    outputs=[multi_input_text, model_path_var],
                )
                
                
                # åŠ¨æ€æ›´æ–°æºè¯­è¨€
                multi_language_model_dropdown.change(
                    fn=self.update_source_languages,  # åŠ è½½æ¨¡å‹å¹¶æ›´æ–°æºè¯­è¨€åˆ—è¡¨
                    inputs=[multi_language_model_dropdown],
                    outputs=[source_lang_dropdown, target_lang_dropdown],
                )

                # åŠ¨æ€ç›®æ ‡è¯­è¨€
                source_lang_dropdown.change(
                    fn=self.update_target_languages,  # æ ¹æ®æºè¯­è¨€æ›´æ–°ç›®æ ‡è¯­è¨€
                    inputs=[source_lang_dropdown, multi_language_model_dropdown],
                    outputs=[target_lang_dropdown],
                )

                
                source_lang_dropdown.change(
                    fn=self.control_input_activation,  # ç¡®ä¿æºè¯­è¨€é€‰æ‹©åï¼Œè¾“å…¥æ¡†å¯ä»¥äº¤äº’
                    inputs=[source_lang_dropdown, target_lang_dropdown, multi_language_model_dropdown],
                    outputs=[multi_input_text]
                )

                target_lang_dropdown.change(
                    fn=self.control_input_activation,  # ç¡®ä¿ç›®æ ‡è¯­è¨€é€‰æ‹©åï¼Œè¾“å…¥æ¡†å¯ä»¥äº¤äº’
                    inputs=[source_lang_dropdown, target_lang_dropdown, multi_language_model_dropdown],
                    outputs=[multi_input_text]
                )

                # è®¾ç½®è¾“å…¥æ¡†çš„ç¿»è¯‘é€»è¾‘
                multi_input_text.change(
                    fn=self.perform_multilang_translation,
                    inputs=[multi_input_text, source_lang_dropdown, target_lang_dropdown],
                    outputs=multi_output_text,
                )

                google_translate_button.click(fn=self.perform_gpt_translation, 
                                inputs=[multi_input_text, source_lang_dropdown, target_lang_dropdown], 
                                outputs=multi_google_output_text)

                

                save_badcase_button.click(fn=self.save_badcase,
                                        inputs=[comments_textbox, multi_input_text, multi_output_text, multi_google_output_text, source_lang_dropdown, target_lang_dropdown, model_path_var],
                                        outputs=gr.Textbox(label="æäº¤çŠ¶æ€", value="ç­‰å¾…ç”¨æˆ·è¾“å…¥åé¦ˆï¼"))
            demo.css = """
            #google_translate_button {
                width: 300px;
                margin: 20px auto;
                padding: 10px 20px;
                font-size: 18px;
                font-weight: bold;
                color: blue;
                background-color: white;
                border: 2px solid blue;
                border-radius: 8px;
                text-align: center;
                cursor: pointer;
                transition: all 0.3s ease;
            }

            #google_translate_button:hover {
                background-color: blue;
                color: blue;
            }

            #google_translate_button:active {
                background-color: darkblue;
                color: white;
            }

            #save_badcase_button {
                width: 10px;  /* æ ¹æ®å†…å®¹è‡ªåŠ¨è°ƒæ•´å®½åº¦ */
                margin: 1px auto;
                padding: 10px; /* å‡å°å†…è¾¹è· */
                font-size: 16px;
                font-weight: bold;
                color: linear-gradient(135deg, #ffa07a, #ff7f50);
                background: linear-gradient(135deg, #ffa07a, #ff7f50);
                border: 2px solid linear-gradient(135deg, #ffa07a, #ff7f50);
                border-radius: 8px;
                text-align: center;
                cursor: pointer;
                transition: all 0.3s ease;
            }

            #save_badcase_button:hover {
                background: linear-gradient(135deg, #ff7f50, #ffa07a);
                color: linear-gradient(135deg, #ffa07a, #ff7f50);
            }

            #save_badcase_button:active {
                background: linear-gradient(135deg, #ffa07a, #ff7f50);
                color: linear-gradient(135deg, #ffa07a, #ff7f50);
            }

            #comments_textbox {
                width: 800px ; 
                margin: 0 auto; /* ä½¿å…¶å±…ä¸­ */
                font-size: 16px; /* è°ƒæ•´å­—ä½“å¤§å° */
                padding: 10px; /* å¢åŠ å†…è¾¹è· */
                box-sizing: border-box; /* ç¡®ä¿å®½åº¦åŒ…å«å†…è¾¹è· */
            }

            """


            # åŠ¨æ€åˆ‡æ¢å¸ƒå±€
            def toggle_translation_mode(mode):
                if mode == "å•è¯­ç§ç¿»è¯‘":
                    return gr.update(visible=True), gr.update(visible=False)
                elif mode == "å¤šè¯­ç§ç¿»è¯‘":
                    return gr.update(visible=False), gr.update(visible=True)

            mode_dropdown.change(
                fn=toggle_translation_mode,
                inputs=[mode_dropdown],
                outputs=[single_language_row, multi_language_row],
            )

        return demo


if __name__ == "__main__":
    app = TranslationApp("config/user_config.json", "config/mapping.jsonl")
    demo = app.render_layout()
    demo.launch(server_name="0.0.0.0", server_port=7856)
